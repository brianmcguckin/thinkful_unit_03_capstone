{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import imblearn\n",
    "import datetime as dt\n",
    "import time\n",
    "import warnings\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import linear_model, ensemble\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "sns.set(style='whitegrid', font_scale=1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set df to manipulate, leave raws accessible\n",
    "train = train_raw.copy()\n",
    "\n",
    "#lowercase column names\n",
    "train.columns = [x.lower() for x in train.columns]\n",
    "\n",
    "#find object datatypes and strip whitespace\n",
    "to_strip = train.select_dtypes(include='object')\n",
    "train[to_strip.columns] = to_strip.apply(lambda x: x.str.strip())\n",
    "\n",
    "#grlivarea outliers\n",
    "train = train[train.grlivarea < 4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "un-transformed: NormaltestResult(statistic=460.3067960010808, pvalue=1.1108342380647651e-100)\n",
      "log: NormaltestResult(statistic=17.417871145375766, pvalue=0.0001651039020773473)\n",
      "log1p: NormaltestResult(statistic=17.41764459169927, pvalue=0.00016512260558467428)\n"
     ]
    }
   ],
   "source": [
    "#target distribution\n",
    "print('un-transformed:', stats.normaltest(a=train['saleprice']))\n",
    "print('log:', stats.normaltest(a=np.log(train['saleprice'])))\n",
    "print('log1p:', stats.normaltest(a=np.log1p(train['saleprice'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same dists, use log1p to play nice with O's\n",
    "features_num = train.dtypes[train.dtypes != 'object'].index\n",
    "train[features_num] = np.log1p(train[features_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing\n",
    "missing_data = train.isnull().sum().sort_values(ascending=False)\n",
    "missing_data = missing_data.reset_index()\n",
    "missing_data.columns = ['variable','rows_missing']\n",
    "missing_data = missing_data[missing_data['rows_missing'] > 0]\n",
    "\n",
    "#drop\n",
    "train.dropna(subset=['electrical'], inplace=True)\n",
    "\n",
    "#categorical\n",
    "train['poolqc'].fillna('no_pool', inplace=True)\n",
    "train['miscfeature'].fillna('no_miscfeat', inplace=True)\n",
    "train['alley'].fillna('no_access', inplace=True)\n",
    "train['fence'].fillna('no_fence', inplace=True)\n",
    "train['fireplacequ'].fillna('no_fireplace', inplace=True)\n",
    "train['garagecond'].fillna('no_garage', inplace=True)\n",
    "train['garagetype'].fillna('no_garage', inplace=True)\n",
    "train['garagefinish'].fillna('no_garage', inplace=True)\n",
    "train['garagequal'].fillna('no_garage', inplace=True)\n",
    "train['bsmtexposure'].fillna('no_bsmt', inplace=True)\n",
    "train['bsmtfintype1'].fillna('no_bsmt', inplace=True)\n",
    "train['bsmtfintype2'].fillna('no_bsmt', inplace=True)\n",
    "train['bsmtcond'].fillna('no_bsmt', inplace=True)\n",
    "train['bsmtqual'].fillna('no_bsmt', inplace=True)\n",
    "train['masvnrtype'].fillna('no_masvnr', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train['masvnrarea'].value_counts()\n",
    "\n",
    "#continuous\n",
    "#train['lotfrontage'].fillna(0, inplace=True)\n",
    "#train['garageyrblt'].fillna(0, inplace=True)\n",
    "#train['masvnrarea'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train)\n",
    "train = train.fillna(train.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.loc[:, ~(train.columns).isin(['saleprice'])]\n",
    "y = train['saleprice']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Models\n",
    "\n",
    "### Vanilla Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: vanilla linear\n",
      "train rmse: 365315666.2935695\n",
      "test rmse: 14253894554.563004\n",
      "test - train =  13888578888.269434\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "cv=10\n",
    "rmse_train = np.sqrt(-cross_val_score(lr, X_train, y_train, cv=cv,\n",
    "                                      scoring='neg_mean_squared_error'))\n",
    "rmse_test = np.sqrt(-cross_val_score(lr, X_test, y_test, cv=cv,\n",
    "                                     scoring='neg_mean_squared_error'))\n",
    "\n",
    "y_pred_train = lr.predict(X_train)\n",
    "y_pred_test = lr.predict(X_test)\n",
    "\n",
    "print('model: vanilla linear')\n",
    "print('train rmse:', rmse_train.mean())\n",
    "print('test rmse:', rmse_test.mean())\n",
    "print('test - train = ', rmse_test.mean() - rmse_train.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Result:__ hahahahaha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2/Ridge Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: ridge\n",
      "alpha: 7.5\n",
      "train rmse: 0.11942683397411594\n",
      "test rmse: 0.13243063429904783\n",
      "test - train =  0.013003800324931897\n"
     ]
    }
   ],
   "source": [
    "#broad alpha search\n",
    "ridge = RidgeCV(alphas=[0.01, 0.025, 0.05, 0.075,\n",
    "                0.1, 0.25, 0.5, 0.075,\n",
    "                1, 2.5, 5, 7.5,\n",
    "                10, 20, 30, 50])\n",
    "\n",
    "ridge.fit(X_train, y_train)\n",
    "rmse_train = np.sqrt(-cross_val_score(ridge, X_train, y_train, cv=cv,\n",
    "                                      scoring='neg_mean_squared_error'))\n",
    "rmse_test = np.sqrt(-cross_val_score(ridge, X_test, y_test, cv=cv,\n",
    "                                     scoring='neg_mean_squared_error'))\n",
    "\n",
    "print('model: ridge')\n",
    "print('alpha:', ridge.alpha_)\n",
    "print('train rmse:', rmse_train.mean())\n",
    "print('test rmse:', rmse_test.mean())\n",
    "print('test - train = ', rmse_test.mean() - rmse_train.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: ridge\n",
      "alpha: 7.0\n",
      "train rmse: 0.1193172500709967\n",
      "test rmse: 0.13154481842444155\n",
      "test - train =  0.012227568353444851\n"
     ]
    }
   ],
   "source": [
    "#tune alpha\n",
    "ridge = RidgeCV(alphas=[7.5,\n",
    "                        5, 5.5, 6, 6.5, 7,\n",
    "                        8, 8.5, 9, 9.5, 10])\n",
    "\n",
    "ridge.fit(X_train, y_train)\n",
    "rmse_train = np.sqrt(-cross_val_score(ridge, X_train, y_train, cv=cv,\n",
    "                                      scoring='neg_mean_squared_error'))\n",
    "rmse_test = np.sqrt(-cross_val_score(ridge, X_test, y_test, cv=cv,\n",
    "                                     scoring='neg_mean_squared_error'))\n",
    "\n",
    "print('model: ridge')\n",
    "print('alpha:', ridge.alpha_)\n",
    "print('train rmse:', rmse_train.mean())\n",
    "print('test rmse:', rmse_test.mean())\n",
    "print('test - train = ', rmse_test.mean() - rmse_train.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Result:__ this is much better, a lot more accurate but still demonstrates some overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1/Lasso Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: lasso\n",
      "alpha: 0.0005\n",
      "train rmse: 0.11723934548496298\n",
      "test rmse: 0.11833346568890905\n",
      "test - train =  0.0010941202039460723\n"
     ]
    }
   ],
   "source": [
    "lasso = LassoCV(alphas=[0.0001, 0.0005,\n",
    "                        0.001, 0.005, \n",
    "                        0.01, 0.05, \n",
    "                        0.1, 0.5,\n",
    "                        1, 5])\n",
    "\n",
    "lasso.fit(X_train, y_train)\n",
    "rmse_train = np.sqrt(-cross_val_score(lasso, X_train, y_train, cv=cv,\n",
    "                                      scoring='neg_mean_squared_error'))\n",
    "rmse_test = np.sqrt(-cross_val_score(lasso, X_test, y_test, cv=cv,\n",
    "                                     scoring='neg_mean_squared_error'))\n",
    "\n",
    "print('model: lasso')\n",
    "print('alpha:', lasso.alpha_)\n",
    "print('train rmse:', rmse_train.mean())\n",
    "print('test rmse:', rmse_test.mean())\n",
    "print('test - train = ', rmse_test.mean() - rmse_train.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: lasso\n",
      "alpha: 0.0005\n",
      "train rmse: 0.11697161987987023\n",
      "test rmse: 0.1184812211503045\n",
      "test - train =  0.0015096012704342715\n"
     ]
    }
   ],
   "source": [
    "lasso = LassoCV(alphas=[0.0005,\n",
    "                        0.0001, 0.0002, 0.0003, 0.0004,\n",
    "                        0.0006, 0.0007, 0.0008, 0.0009, 0.001])\n",
    "\n",
    "lasso.fit(X_train, y_train)\n",
    "rmse_train = np.sqrt(-cross_val_score(lasso, X_train, y_train, cv=cv,\n",
    "                                      scoring='neg_mean_squared_error'))\n",
    "rmse_test = np.sqrt(-cross_val_score(lasso, X_test, y_test, cv=cv,\n",
    "                                     scoring='neg_mean_squared_error'))\n",
    "\n",
    "print('model: lasso')\n",
    "print('alpha:', lasso.alpha_)\n",
    "print('train rmse:', rmse_train.mean())\n",
    "print('test rmse:', rmse_test.mean())\n",
    "print('test - train = ', rmse_test.mean() - rmse_train.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Result:__ Best results so far, picked the same value for alpha in both searches, L1 test rmse's of 0.11833 and 0.11848 are the lowest yet, and where arrived at with a lot less overfitting than L2 LR model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'max_features': 303, 'n_estimators': 300}\n",
      "runtime:  79.14090499999998\n"
     ]
    }
   ],
   "source": [
    "#broad param search using GridSearchCV\n",
    "rfr = ensemble.RandomForestRegressor()\n",
    "params = [{'n_estimators':[10, 50, 75, 100, 200, 300, 400, 500],\n",
    "           'max_features':[1, 303]}]\n",
    "\n",
    "start_time = time.clock()\n",
    "grid = GridSearchCV(estimator=rfr,\n",
    "                    param_grid=params,\n",
    "                    scoring='neg_mean_squared_error')\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print('params:', grid.best_params_)\n",
    "print('runtime: ', time.clock() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'max_features': 303, 'n_estimators': 350}\n",
      "runtime:  87.14608899999996\n"
     ]
    }
   ],
   "source": [
    "#fine param search\n",
    "params = [{'n_estimators':[300,\n",
    "                           225, 250, 275,\n",
    "                           325, 350, 375],\n",
    "           'max_features':[303]}]\n",
    "\n",
    "start_time = time.clock()\n",
    "grid = GridSearchCV(estimator=rfr,\n",
    "                    param_grid=params,\n",
    "                    scoring='neg_mean_squared_error')\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print('params:', grid.best_params_)\n",
    "print('runtime: ', time.clock() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: random forest\n",
      "train rmse: 0.14591969608777441\n",
      "test rmse: 0.14707621650774533\n",
      "test - train =  0.0011565204199709134\n",
      "runtime:  43.62875600000007\n"
     ]
    }
   ],
   "source": [
    "#different n_estimators but the same results, use the lower n_estimators\n",
    "rfr = ensemble.RandomForestRegressor(n_estimators=350, max_features=303)\n",
    "\n",
    "start_time = time.clock()\n",
    "rfr.fit(X_train, y_train)\n",
    "\n",
    "cv=5\n",
    "rmse_train = np.sqrt(-cross_val_score(rfr, X_train, y_train, cv=cv,\n",
    "                                      scoring='neg_mean_squared_error'))\n",
    "rmse_test = np.sqrt(-cross_val_score(rfr, X_test, y_test, cv=cv,\n",
    "                                     scoring='neg_mean_squared_error'))\n",
    "\n",
    "print('model: random forest')\n",
    "print('train rmse:', rmse_train.mean())\n",
    "print('test rmse:', rmse_test.mean())\n",
    "print('test - train = ', rmse_test.mean() - rmse_train.mean())\n",
    "print('runtime: ', time.clock() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Result:__ decent accuracy, not overfitting too much, but not as low rmse as L1 regr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'learning_rate': 0.01, 'loss': 'ls', 'max_depth': 4, 'max_features': 303, 'n_estimators': 750, 'subsample': 0.25}\n",
      "runtime:  952.3800260000003\n"
     ]
    }
   ],
   "source": [
    "gbr = ensemble.GradientBoostingRegressor()\n",
    "params = [{'loss':['ls'],\n",
    "           'learning_rate':[0.001, 0.01, 0.1, 1],\n",
    "           'n_estimators':[250, 500, 750],\n",
    "           'max_depth':[2, 3, 4],\n",
    "           'subsample':[0.25, 0.5, 0.75, 1],\n",
    "           'max_features':[1, 303]}]\n",
    "\n",
    "start_time = time.clock()\n",
    "grid = GridSearchCV(estimator=gbr, param_grid=params, scoring='neg_mean_squared_error')\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "print('params:', grid.best_params_)\n",
    "print('runtime: ', time.clock() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skip this for now it takes 15+ min to run\n",
    "#refine params\n",
    "#params = [{'loss':['ls'],\n",
    "#           'learning_rate':[0.01,\n",
    "#                            0.0075, 0.005,\n",
    "#                            0.025, 0.05,],\n",
    "#           'n_estimators':[750,\n",
    "#                           700, 725, 775, 800],\n",
    "#           'max_depth':[4],\n",
    "#           'subsample':[0.25,\n",
    "#                        0.1, 0.2,\n",
    "#           'max_features':[303]}]\n",
    "\n",
    "#start_time = time.clock()\n",
    "#grid = GridSearchCV(estimator=gbr, param_grid=params, scoring='neg_mean_squared_error')\n",
    "\n",
    "#grid.fit(X_train, y_train)\n",
    "#print('params:', grid.best_params_)\n",
    "#print('runtime: ', time.clock() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: gradient boosting\n",
      "train rmse: 0.12376588473757395\n",
      "test rmse: 0.11890135869366411\n",
      "test - train =  -0.004864526043909842\n",
      "runtime:  29.048637999999755\n"
     ]
    }
   ],
   "source": [
    "gbr = ensemble.GradientBoostingRegressor(loss='ls',\n",
    "                                        learning_rate=0.01,\n",
    "                                        n_estimators=750,\n",
    "                                        max_depth=4,\n",
    "                                        subsample=0.25,\n",
    "                                        max_features=303)\n",
    "\n",
    "start_time = time.clock()\n",
    "gbr.fit(X_train, y_train)\n",
    "\n",
    "cv=5\n",
    "rmse_train = np.sqrt(-cross_val_score(gbr, X_train, y_train, cv=cv,\n",
    "                                      scoring='neg_mean_squared_error'))\n",
    "rmse_test = np.sqrt(-cross_val_score(gbr, X_test, y_test, cv=cv,\n",
    "                                     scoring='neg_mean_squared_error'))\n",
    "\n",
    "print('model: gradient boosting')\n",
    "print('train rmse:', rmse_train.mean())\n",
    "print('test rmse:', rmse_test.mean())\n",
    "print('test - train = ', rmse_test.mean() - rmse_train.mean())\n",
    "print('runtime: ', time.clock() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Result:__ not ideal, test set outperformed train set, probably needs further parameter tuning but a huge weak point here is the amount of time it takes to tune the model (sometimes 20+ minutes for a gridsearch). I'm not confident this will outperform L1 Regr, perhaps with further feature engineering. L1 Lasso is the winner here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
